{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Recognition with Deep Belief Networks\n",
    "-------------------------------------\n",
    "\n",
    "<div style=\"text-align: right\">Alfonso Irarrazaval · Gregory Schuit</div>\n",
    "<div style=\"text-align: right\">IIC3695 - Tópicos Avanzados de Inteligencia de Máquina</div>\n",
    "<div style=\"text-align: right\">Proyecto Semestral</div>\n",
    "<div style=\"text-align: right\">2019´1</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "-----------------\n",
    "\n",
    "Alguna vez ha ocurrido que mientras revisas fotos de vacaciones pasadas, no puedes recordar exactamente que monumento o lugar histórico era ese para el que posaste tan felizmente? Para eso sirve el reconocimiento de Puntos de Referencia (Landmark Recognition de aquí en adelante), el que consiste precisamente en detectar que *Landmarks* están presentes en una foto. ([1])  \n",
    "Este es, en esencia, es un problema de reconocimiento de imagen, por lo que resulta intuitivo acudir a *Machine Learning* para encontrar su solución. El mayor obstaculo que enfrentan los problemas de este tipo es que hay demasiados *Landmarks* en que fijarse, por lo que se necesita un *dataset* muy grande para poder entrenar este modelo eficientemente. En este caso, ese detalle ha sido solucionado por Google®, ya que en su desafío presentado en Kaggle® [1] facilita el *dataset* mas grande de este tipo a la fecha.\n",
    "\n",
    "El enfoque de este trabajo será centrado en *Bayesian Machine Learning*, específicamente en *Deep Belief Networks*, las cuales consideramos son un approach interesante para este tipo de problemas ya que permiten un aprendizaje modularizado de *features* (se detallará esto más adelante).\n",
    "\n",
    "Se comenzará explicando la teoría detras de las *Deep Belief Networks*, detallando sus fundamentos probabilisticos y los elementos que las componen, para luego pasar al problema en cuestión y nuestra implementación de una posible solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Teoría\n",
    "-----------------\n",
    "### 2.1. Modelos Gráficos Probabilísticos\n",
    "#### 2.1.1 Grafos dirigidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Bajo el contexto de la teoría de probabilidades, existe un campo de estudio dedicado a representar dependencias entre eventos mediante grafos. Uno de los principales objetivos por los que nacen estos modelos gráficos es poder factorizar una distribución conjunta mediante probabilidades condicionales. Por ejemplo, la siguiente ecuación factoriza la probabilidad conjunta según el gráfico de la figura.\n",
    "</div>\n",
    "\n",
    "![image.png](img/bayesian_network.PNG)\n",
    "\n",
    "<div style=\"text-align: center\">$P(a, b, c) = P(a)P(b | a)P(c | a,b)  $ </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;En general, la factorización guiada por una red de bayes se da según la siguiente fórmula:\n",
    "</div>\n",
    "<br>   \n",
    "<div style=\"text-align: center\">$P(x) = \\prod_{k=1}^{K} P(x_{k}|pa_{k})$, </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "donde $pa_{k}$ es el conjunto de todos los eventos que apuntan a $x_k$. Es importante notar que este tipo de grafos no puede poseer ciclos.\n",
    "</div>\n",
    "<br>  \n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Este tipo de factorización resulta muy útil al momento de generar muestras de una distribución compleja de varias variables. En el ejemplo anterior, el proceso para generar muestras de la conjunta es el siguiente: primero se genera una muestra de $a$ según su propia distribución, luego, dada la muestra de $a$, podemos generar una muestra de $b$ de manera directa, y finalmente, dada las muestras de $a$ y de $b$, condicionamos a $c$ y extraemos una muestra. El resultado final de la muestra son los tres valores extraídos en el proceso. A este proceso se le denomina _ancestral sampling_.\n",
    "</div>\n",
    "<br>            \n",
    "         \n",
    "          \n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;En el contexto de modelos de inferencia, estos grafos pueden simplicar mucho el cómputo de predicciones, incluyendo nodos para parámetros, priors, hiperparámetros, etc. Un ejemplo rápido es la regresión lineal bayesiana que se muestra a continuación. Para más detalle, ver (Bishop, 2006).\n",
    "</div>\n",
    "\n",
    "<img src=\"img/regresion_bayes_network.PNG\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Grafos no-dirigidos\n",
    "<br>                 \n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Si bien las redes dirigidas descritas anteriormente simplifican de gran manera el modelamiento de problemas, podemos simplicar aún más las cosas para adecuarnos mejor a cierto tipo de problemas. Un problema de las redes dirigidas es que no se pueden modelar problemas sin generar ciclos (Koller & Friedman, Cap. 4.1, 2009). Además, el proceso de factorización dado un grafo extenso dirigido, que se realiza por medio de un algoritmo llamado _d-separation_, puede llegar a ser muy complejo (Bishop, 2006). En cambio, el proceso para determinar independencia entre grupos de nodos en un grafo no dirigido es mucho más simple. Considere la siguiente figura:</div>\n",
    "<br>\n",
    "<img src=\"img/red_no_dirigida.PNG\" width=\"300\">\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Si queremos determinar si la relación $A \\perp B\\ |\\ C\\ $ (i.e. $A$ y $B$ son independientes dado $C$) se cumple, basta con mirar todos los caminos que van de $A$ a $B$, y ver si son bloquados por $C$. Si se cumple que todos los caminos pasan por $C$, se dice que $C$ bloquea los caminos, dejando a $A$ y $B$ independientes si se observa $C$. En caso de que exista al menos una conexión que no pase por $C$, la propiedad de independencia no necesariamente se cumple.\n",
    "</div>\n",
    "\n",
    "Definir funcion _factor_   \n",
    "Definir el por que de la funcion de energía, argumento de los cliques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Boltzmann Machines\n",
    "\n",
    "#### 2.2.2 Gibbs Sampling\n",
    "Gibbs Sampling es un método ampliamente ocupado de Markov Chain Monte Carlo, el cual puede ser visto como un caso particular del algoritmo Metropolis-Hastings [2].\n",
    "\n",
    "Consideramos la siguiente distribución de la que deseamos samplear, la cual tiene algun estado inicial para la MC:  \n",
    "<div style=\"text-align: center\">$p(\\Theta) = p(\\theta_{1}, \\theta_{2}, ... , \\theta_{m})$</div>  \n",
    "Entonces, cada uno de los pasos de Gibbs consiste en reemplazar el valor de una de las variables $\\theta_{i}$ por un valor sacado de la distribución de esa variable, condicionada por todas las demás variables del modelo\n",
    "<div style=\"text-align: center\">$p(\\theta_{i}|\\Theta - \\{\\theta_{i}\\})$</div>  \n",
    "Este proceso se repite reiteradas veces iterando sobre las variables.\n",
    "\n",
    "En este caso, se utiliza Gibbs para simular la distribución de la *Markov Random Field* correspondiente. \n",
    "<div style=\"text-align: center\">$MRF \\rightarrow p(X) = p(X_{1}, X_{2}, ... , X_{m})$</div> \n",
    "En cada iteración de gibbs se actualizará el estado de la MRF a p(X^{t}) = p(X*{t}_{1}, X^{t}_{2}, ... , X^{t}_{m})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Deep Belief Networks (DBN's)\n",
    "+ introducción a las DBN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Image Recognition with DBN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problema\n",
    "-----------------\n",
    "Como se mencionó anteriormente, lo que se desea en este trabajo es desarrollar un algoritmo que se adhiera al principio de *Bayesian Machine Learning* para detectar correctamente si es que una foto presenta un landmark o no, y entregar el nombre de aquel landmark en caso de un resultado psitivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descripción de datos\n",
    "\n",
    "Los datos a utilizar corresponden al dataset expuesto en [1], pero dado que este dataset contiene >2.000.00 de imágenes y pesa >400GB, para efectos de simplicidad se utilizará un subset de éste que contiene todas las imágenes de los 14 *landmarks* con más imágenes presentes en el dataset (lo que de igual manera corresponde a 116.610 imágenes en 30.9 GB). El método de extracción de estas imagenes se detalla en el archivo downloader.py.  \n",
    "La información se encuentra separada en 2 partes: \n",
    "+ Conjunto de imágenes en formato *.jpg* con landmarks presentes en ellas.\n",
    "+ CSV relacionando nombre de archivo con landmark presente\n",
    "En otras palabras, el archivo de imágenes corresponderá a el input de nuestro algoritmo, y del csv obtendremos el target respectivo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Approach propuesto\n",
    "\n",
    "Una propuesta respecto al manejo de datos para la implementación, es comenzar usando un modelo que vectorice las imágenes, para luego buscar en esas imagenes patrones que representen a los distintos landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referencias - Bibliografía\n",
    "\n",
    "**[ 1 ]**  *Google Landmark Recognition Challenge* https://www.kaggle.com/c/landmark-recognition-challenge  \n",
    "**[ 2 ]**  C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006\n",
    "**[ 3 ]**  \n",
    "**[ 4 ]**  \n",
    "**[ 5 ]**  \n",
    "**[ 6 ]**  \n",
    "**[ 7 ]**  \n",
    "**[ 8 ]**  \n",
    "**[ 9 ]**  \n",
    "**[ 10 ]**  \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton    \n",
    "Hinton    \n",
    "Hinton  \n",
    "Hinton    \n",
    "Hinton  \n",
    "Hinton    \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton  \n",
    "Hinton  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
