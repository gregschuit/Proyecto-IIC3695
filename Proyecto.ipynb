{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Recognition with Deep Belief Networks\n",
    "-------------------------------------\n",
    "\n",
    "<div style=\"text-align: right\">Alfonso Irarrazaval · Gregory Schuit</div>\n",
    "<div style=\"text-align: right\">IIC3695 - Tópicos Avanzados de Inteligencia de Máquina</div>\n",
    "<div style=\"text-align: right\">Proyecto Semestral</div>\n",
    "<div style=\"text-align: right\">2019´1</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "-----------------\n",
    "<div style=\"text-align: justify\">\n",
    "Alguna vez ha ocurrido que mientras revisas fotos de vacaciones pasadas, no puedes recordar exactamente que monumento o lugar histórico era ese para el que posaste tan felizmente? Para eso sirve el reconocimiento de Puntos de Referencia (Landmark Recognition de aquí en adelante), el que consiste precisamente en detectar que *Landmarks* están presentes en una foto [1].\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "Este es, en esencia, es un problema de reconocimiento de imagen, por lo que resulta intuitivo acudir a *Machine Learning* para encontrar su solución. El mayor obstaculo que enfrentan los problemas de este tipo es que hay demasiados *Landmarks* en que fijarse, por lo que se necesita un *dataset* muy grande para poder entrenar este modelo eficientemente. En este caso, ese detalle ha sido solucionado por Google®, ya que en su desafío presentado en Kaggle® [1] facilita el *dataset* mas grande de este tipo a la fecha.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "El enfoque de este trabajo será centrado en *Bayesian Machine Learning*, específicamente en *Deep Belief Networks*, las cuales consideramos son un approach interesante para este tipo de problemas ya que permiten un aprendizaje modularizado de *features* (se detallará esto más adelante).\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "Se comenzará explicando la teoría detras de las *Deep Belief Networks*, detallando sus fundamentos probabilisticos y los elementos que las componen, para luego pasar al problema en cuestión y nuestra implementación de una posible solución.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Teoría\n",
    "-----------------\n",
    "### 2.1. Modelos Gráficos Probabilísticos\n",
    "#### 2.1.1 Grafos dirigidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Bajo el contexto de la teoría de probabilidades, existe un campo de estudio dedicado a representar dependencias entre eventos mediante grafos. Uno de los principales objetivos por los que nacen estos modelos gráficos es poder factorizar una distribución conjunta mediante probabilidades condicionales. Por ejemplo, la siguiente ecuación factoriza la probabilidad conjunta según el gráfico de la figura.\n",
    "</div>\n",
    "\n",
    "![image.png](img/bayesian_network.PNG)\n",
    "\n",
    "<div style=\"text-align: center\">$P(a, b, c) = P(a)P(b | a)P(c | a,b)  $ </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;En general, la factorización guiada por una red de bayes se da según la siguiente fórmula:\n",
    "</div>\n",
    "<br>   \n",
    "<div style=\"text-align: center\">$P(x) = \\prod_{k=1}^{K} P(x_{k}|pa_{k})$, </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "donde $pa_{k}$ es el conjunto de todos los eventos que apuntan a $x_k$. Es importante notar que este tipo de grafos no puede poseer ciclos.\n",
    "</div>\n",
    "<br>  \n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Este tipo de factorización resulta muy útil al momento de generar muestras de una distribución compleja de varias variables. En el ejemplo anterior, el proceso para generar muestras de la conjunta es el siguiente: primero se genera una muestra de $a$ según su propia distribución, luego, dada la muestra de $a$, podemos generar una muestra de $b$ de manera directa, y finalmente, dada las muestras de $a$ y de $b$, condicionamos a $c$ y extraemos una muestra. El resultado final de la muestra son los tres valores extraídos en el proceso. A este proceso se le denomina _ancestral sampling_.\n",
    "</div>\n",
    "<br>            \n",
    "         \n",
    "          \n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;En el contexto de modelos de inferencia, estos grafos pueden simplicar mucho el cómputo de predicciones, incluyendo nodos para parámetros, priors, hiperparámetros, etc. Un ejemplo rápido es la regresión lineal bayesiana que se muestra a continuación. Para más detalle, ver (Bishop, 2006).\n",
    "</div>\n",
    "\n",
    "<img src=\"img/regresion_bayes_network.PNG\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Grafos no-dirigidos\n",
    "<br>                 \n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Si bien las redes dirigidas descritas anteriormente simplifican de gran manera el modelamiento de problemas, podemos simplicar aún más las cosas para adecuarnos mejor a cierto tipo de problemas. Un problema de las redes dirigidas es que no se pueden modelar problemas sin generar ciclos (Koller & Friedman, Cap. 4.1, 2009). Además, el proceso de factorización dado un grafo extenso dirigido, que se realiza por medio de un algoritmo llamado _d-separation_, puede llegar a ser muy complejo (Bishop, 2006). En cambio, el proceso para determinar independencia entre grupos de nodos en un grafo no dirigido es mucho más simple. Considere la siguiente figura:</div>\n",
    "<br>\n",
    "<img src=\"img/red_no_dirigida.PNG\" width=\"300\">\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Si queremos determinar si la relación $A \\perp B\\ |\\ C\\ $ (i.e. $A$ y $B$ son independientes dado $C$) se cumple, basta con mirar todos los caminos que van de $A$ a $B$, y ver si son bloquados por $C$. Si se cumple que todos los caminos pasan por $C$, se dice que $C$ bloquea los caminos, dejando a $A$ y $B$ independientes si se observa $C$. En caso de que exista al menos una conexión que no pase por $C$, la propiedad de independencia no necesariamente se cumple.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;En este tipo de grafos, llamados _Markov fields_ o _Markov Networks_, cada arista posee un peso que puede interpretarse como una \"afinidad\" o \"compatibilidad\" entre los eventos que conecta. Es importante no confundir estos pesos con las probabilidades de los eventos o con las probabilidades condicionales. Estos pesos se denominan _factores_, y permiten factorizar una probabilidad conjunta de la siguiente forma:\n",
    "</div>\n",
    "<br>\n",
    "<img src=\"img/misconception.PNG\" width=\"150\">\n",
    "<br>\n",
    "<div style=\"text-align: center\">$P(A, B, C, D) = \\phi(A, B) · \\phi(B, C) ·\\phi(C, D) ·\\phi(A, D)$</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "donde se logran plasmar relaciones de independencia entre $A$ y $C$ dados B y D, y entre $B$ y $D$ dados $A$ y $C$. Estas relaciones de independencia son imposibles de modelar mediante una red de bayes, tal y cómo se revisa en (Koller, Friedman, 2009), en donde se modela la situacion de 4 estudiantes ($A$, $B$, $C$ y $D$), que sólo se hablan entre los que sí poseen aristas, y que cada uno puede o no tener un mal entendido en la materia vista en clases. Este ejemplo es interesante, pero no se explicará porque sale del alcance de este informe.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;El modelamiento de probabilidades conjuntas mediante una red de markov, es una generalización del método de factorización visto anteriormente para redes de Bayes (basta con definir $\\phi$ igual a las probabilidades condicionales que correspondan), por lo que la capacidad de modelamiento de una red de Markov resulta ser superior. \n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Formalmente, definimos la probabilidad conjunta de un vector $x$ como la _distribución de Gibbs_, correspondiente a una red de Markov, tal y como sigue:\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: center\">$P(x_1, ..., x_n) = \\phi(D_1) · \\phi(D_2) ··· \\phi(D_m) · (1/Z)$</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "siendo Z la constante de normalización sobre todos los posibles x.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Una propiedad importante de esta factorización es que, si {$D_1$, ..., $D_m$} es un conjunto de cliques de la red, entonces la factorización puede levarse a cabo. De esto se desprende directamente que si estos cliques son máximos, estamos reduciendo lo más posible la cantidad de parámetros de la distribución factorizada.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Boltzmann Machines\n",
    "\n",
    "Las máquinas de Boltzmann, nacen como grafos no dirigidos (redes de markov), y constan, además de pesos en cada arista, a factores para cada uno de sus nodos, logrando así una capacidad aún mayor de modelamiento. De esta forma, definimos la suma de los logaritmos de los factores de la red como:\n",
    "<br>\n",
    "<img src=\"img/energy.PNG\" width=\"400\">\n",
    "<br>\n",
    "\n",
    "Esta función se denomina funcion de energía, y será la principal componente a optimizar en las RBM.\n",
    "\n",
    "#### 2.2.2 Gibbs Sampling\n",
    "Gibbs Sampling es un método ampliamente ocupado de Markov Chain Monte Carlo, el cual puede ser visto como un caso particular del algoritmo Metropolis-Hastings [2].\n",
    "\n",
    "Consideramos la siguiente distribución de la que deseamos samplear, la cual tiene algun estado inicial para la MC:  \n",
    "<div style=\"text-align: center\">$p(\\Theta) = p(\\theta_{1}, \\theta_{2}, ... , \\theta_{m})$</div>  \n",
    "Entonces, cada uno de los pasos de Gibbs consiste en reemplazar el valor de una de las variables $\\theta_{i}$ por un valor sacado de la distribución de esa variable, condicionada por todas las demás variables del modelo\n",
    "<div style=\"text-align: center\">$p(\\theta_{i}|\\Theta - \\{\\theta_{i}\\})$</div>  \n",
    "Este proceso se repite reiteradas veces iterando sobre las variables.\n",
    "\n",
    "En este caso, se utiliza Gibbs para simular la distribución de la *Markov Random Field* correspondiente. \n",
    "<div style=\"text-align: center\">$MRF \\rightarrow p(X) = p(X_{1}, X_{2}, ... , X_{m})$</div> \n",
    "En cada iteración de gibbs se actualizará el estado de la MRF a p(X^{t}) = p(X*{t}_{1}, X^{t}_{2}, ... , X^{t}_{m})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Deep Belief Networks (DBN's)\n",
    "+ introducción a las DBN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Image Recognition with DBN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problema\n",
    "-----------------\n",
    "Como se mencionó anteriormente, lo que se desea en este trabajo es desarrollar un algoritmo que se adhiera al principio de *Bayesian Machine Learning* para detectar correctamente si es que una foto presenta un landmark o no, y entregar el nombre de aquel landmark en caso de un resultado psitivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descripción de datos\n",
    "\n",
    "Los datos a utilizar corresponden al dataset expuesto en [1], pero dado que este dataset contiene >2.000.00 de imágenes y pesa >400GB, para efectos de simplicidad se utilizará un subset de éste que contiene todas las imágenes de los 14 *landmarks* con más imágenes presentes en el dataset (lo que de igual manera corresponde a 116.610 imágenes en 30.9 GB). El método de extracción de estas imagenes se detalla en el archivo downloader.py.  \n",
    "La información se encuentra separada en 2 partes: \n",
    "+ Conjunto de imágenes en formato *.jpg* con landmarks presentes en ellas.\n",
    "+ CSV relacionando nombre de archivo con landmark presente\n",
    "En otras palabras, el archivo de imágenes corresponderá a el input de nuestro algoritmo, y del csv obtendremos el target respectivo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Approach propuesto\n",
    "\n",
    "\n",
    "Una propuesta respecto al manejo de datos para la implementación, es comenzar usando un modelo que vectorice las imágenes, para luego buscar en esas imagenes patrones que representen a los distintos landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referencias - Bibliografía\n",
    "\n",
    "**[ 1 ]**  *Google Landmark Recognition Challenge* https://www.kaggle.com/c/landmark-recognition-challenge  \n",
    "**[ 2 ]**  Falta poner todos los papers y los libros\n",
    "**[ 3 ]**  \n",
    "**[ 4 ]**  \n",
    "**[ 5 ]**  \n",
    "**[ 6 ]**  \n",
    "**[ 7 ]**  \n",
    "**[ 8 ]**  \n",
    "**[ 9 ]**  \n",
    "**[ 10 ]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
